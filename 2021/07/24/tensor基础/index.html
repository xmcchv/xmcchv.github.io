<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="云间之龙">
    
    <title>
        
            tensor基础 |
        
        云间小栈
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/avatar.jpg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"xmcchv.github.io","root":"/","language":"zh-CN","path":"search.xml"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":false,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.jpg","favicon":"/images/avatar.jpg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"凡心所向，素履所往；生如逆旅，一苇以航"},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":false},"lazyload":{"enable":true},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
  </script>
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                云间小栈
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                标签
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               target="_blank" rel="noopener" href="https://xmcchv.vercel.app/zh-CN/"
                            >
                                下载站
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                关于
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">标签</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       target="_blank" rel="noopener" href="https://xmcchv.vercel.app/zh-CN/">下载站</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">关于</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">tensor基础</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.jpg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">云间之龙</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2021-07-24 17:39:29</span>
        <span class="mobile">2021-07-24 17:39</span>
    </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/pytorch/">pytorch</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h2 id="张量的创建与常用方法"><a href="#张量的创建与常用方法" class="headerlink" title="张量的创建与常用方法"></a>张量的创建与常用方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a1=np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">a1</span><br></pre></td></tr></table></figure>




<pre><code>array([[1, 2, 3],
       [4, 5, 6]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=torch.tensor([a1,a1])</span><br><span class="line">t3</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[1, 2, 3],
         [4, 5, 6]],

        [[1, 2, 3],
         [4, 5, 6]]], dtype=torch.int32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3.size()</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([2, 2, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3.ndim</span><br></pre></td></tr></table></figure>




<pre><code>3
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(t3)</span><br></pre></td></tr></table></figure>




<pre><code>2
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3.flatten()</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6], dtype=torch.int32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.tensor([<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">t1</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转化为两行，一列的张量</span></span><br><span class="line">t1.reshape(<span class="number">2</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1],
        [2]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1.reshape(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">t2</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1, 2, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.reshape([<span class="number">3</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1],
        [2],
        [3]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.reshape(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1, 2, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3.reshape(<span class="number">12</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6], dtype=torch.int32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3.reshape(<span class="number">2</span>,<span class="number">6</span>) <span class="comment"># 转换为两行六列的张量</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1, 2, 3, 4, 5, 6],
        [1, 2, 3, 4, 5, 6]], dtype=torch.int32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.ones([<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1., 1., 1.],
        [1., 1., 1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.eye(<span class="number">5</span>)  <span class="comment"># 单位矩阵</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1</span><br><span class="line">torch.diag(t1) <span class="comment"># 不能使用list直接创建对角矩阵</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1, 0],
        [0, 2]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.rand(<span class="number">2</span>,<span class="number">3</span>) <span class="comment"># rand服从0-1均匀分布</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0.9925, 0.4613, 0.1272],
        [0.6944, 0.3979, 0.4879]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randn(<span class="number">2</span>,<span class="number">3</span>) <span class="comment"># 服从标准正态分布的张量</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0.7202, -1.3448,  1.1586],
        [-1.3567, -0.6265,  0.6884]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.normal(<span class="number">2</span>,<span class="number">3</span>,size=(<span class="number">2</span>,<span class="number">2</span>)) <span class="comment"># 均值为2，标准差为3的张量  指定正态分布</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[-1.8283,  0.6573],
        [ 0.7957,  4.2425]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randint(<span class="number">1</span>,<span class="number">10</span>,[<span class="number">2</span>,<span class="number">4</span>]) <span class="comment"># 在1-10之间随机抽取整数，组成两行四列的张量</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[2, 8, 1, 3],
        [4, 6, 9, 5]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.arange(<span class="number">5</span>)  <span class="comment"># 默认每隔1取</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([0, 1, 2, 3, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.arange(<span class="number">1</span>,<span class="number">5</span>,<span class="number">0.5</span>) <span class="comment"># 从1-5 左闭右开 每隔0.5取值一个</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000, 4.5000])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.linspace(<span class="number">1</span>,<span class="number">5</span>,<span class="number">3</span>) <span class="comment"># 从1-5 闭区间 等距取三个数</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([1., 3., 5.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.linspace(<span class="number">1</span>,<span class="number">9</span>,<span class="number">6</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1.0000, 2.6000, 4.2000, 5.8000, 7.4000, 9.0000])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.empty(<span class="number">2</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[8.1717e+20, 2.1274e+23, 8.5032e+20],
        [1.0616e+21, 4.3445e-05, 2.0432e+20]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.full([<span class="number">2</span>,<span class="number">4</span>],<span class="number">2</span>)  <span class="comment"># 两行四列 填充2 的张量</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[2, 2, 2, 2],
        [2, 2, 2, 2]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.full_like(t1,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([2, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randint_like(t2,<span class="number">1</span>,<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([5, 1, 5])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.arange(<span class="number">1</span>,<span class="number">11</span>)</span><br><span class="line">t1</span><br></pre></td></tr></table></figure>




<pre><code>tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1.numpy()</span><br></pre></td></tr></table></figure>




<pre><code>array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int64)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.array(t1)</span><br></pre></td></tr></table></figure>




<pre><code>array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int64)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1.tolist()</span><br></pre></td></tr></table></figure>




<pre><code>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span>(t1)   <span class="comment"># 一维张量由零维张量组成 二维由一维组成</span></span><br></pre></td></tr></table></figure>




<pre><code>[tensor(1),
 tensor(2),
 tensor(3),
 tensor(4),
 tensor(5),
 tensor(6),
 tensor(7),
 tensor(8),
 tensor(9),
 tensor(10)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1</span><br></pre></td></tr></table></figure>




<pre><code>tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t11=t1.clone()</span><br><span class="line">t11</span><br></pre></td></tr></table></figure>




<pre><code>tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t1[<span class="number">0</span>]=<span class="number">200</span></span><br><span class="line"><span class="built_in">print</span>(t1)</span><br><span class="line"><span class="built_in">print</span>(t11)</span><br></pre></td></tr></table></figure>

<pre><code>tensor([200,   2,   3,   4,   5,   6,   7,   8,   9,  10])
tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])
</code></pre>
<h2 id="张量的索引、分片、合并以及维度调整"><a href="#张量的索引、分片、合并以及维度调整" class="headerlink" title="张量的索引、分片、合并以及维度调整"></a>张量的索引、分片、合并以及维度调整</h2><pre><code>张量作为有序的序列，也是具备数值索引的功能，并且基本索引方法和python原生的列表、numpy中的数组基本一致，当然，所不同的是，pytorch中还定义了一种采用函数来进行索引的方式。
而作为pytorch中基本数据类型，张量即具备了列表、数组的基本功能，同时还充当着向量、矩阵、数据框等重要的数据结构，因此pytorch中也设置了非常完备的张量合并与变换的操作
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>

<h4 id="一维张量索引"><a href="#一维张量索引" class="headerlink" title="一维张量索引"></a>一维张量索引</h4><p>一维张量的索引过程和python原生对象类型的索引一致,[start:end,step]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.arange(<span class="number">1</span>,<span class="number">11</span>)</span><br><span class="line">t1</span><br></pre></td></tr></table></figure>




<pre><code>tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1[<span class="number">1</span>:<span class="number">8</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([2, 3, 4, 5, 6, 7, 8])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1[<span class="number">1</span>:<span class="number">8</span>:<span class="number">2</span>] <span class="comment"># 索引其中2-9号元素，左闭右开，每隔2个数取一个</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([2, 4, 6, 8])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1[<span class="number">1</span>: :<span class="number">2</span>] <span class="comment"># 从第二个元素开始索引，一直到结尾，并且每隔两个数取一个</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([ 2,  4,  6,  8, 10])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1[:<span class="number">8</span>:<span class="number">2</span>] <span class="comment"># 第一个元素到第九个元素（不包含）</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([1, 3, 5, 7])
</code></pre>
<p>在张量的索引中，step位必须大于0</p>
<h4 id="二维张量"><a href="#二维张量" class="headerlink" title="二维张量"></a>二维张量</h4><p>二维张量可以视为两个一维张量组合而成，在实际的索引过程中，需要用逗号进行分割，分别不表示对哪个一维张量进行索引，以及具体的一维张量的索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=torch.arange(<span class="number">1</span>,<span class="number">10</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">t2</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2[<span class="number">0</span>,<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor(2)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2[<span class="number">0</span>,::<span class="number">2</span>]  <span class="comment"># 表示索引第一行、每隔两个元素取一个</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([1, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2[::<span class="number">2</span>,::<span class="number">2</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1, 3],
        [7, 9]])
</code></pre>
<h4 id="三维张量"><a href="#三维张量" class="headerlink" title="三维张量"></a>三维张量</h4><p> 即二维张量组成的三维张量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=torch.arange(<span class="number">1</span>,<span class="number">28</span>).reshape(<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">t3</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[ 1,  2,  3],
         [ 4,  5,  6],
         [ 7,  8,  9]],

        [[10, 11, 12],
         [13, 14, 15],
         [16, 17, 18]],

        [[19, 20, 21],
         [22, 23, 24],
         [25, 26, 27]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor(14)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3[<span class="number">1</span>,<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([13, 14, 15])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[10, 11, 12],
        [13, 14, 15],
        [16, 17, 18]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3[<span class="number">1</span>,::<span class="number">2</span>,::<span class="number">2</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[10, 12],
        [16, 18]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([3, 3, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">indices=torch.tensor([<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">indices</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([3, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.index_select(t2,<span class="number">0</span>,indices) <span class="comment"># dim参数为0，代表在shape的第一个维度上索引 </span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[4, 5, 6],
        [7, 8, 9]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.index_select(t2,<span class="number">1</span>,indices) <span class="comment"># dim参数为1，代表在shape的第二个维度上索引</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[2, 3],
        [5, 6],
        [8, 9]])
</code></pre>
<h2 id="tensor-view-方法"><a href="#tensor-view-方法" class="headerlink" title="tensor.view()方法"></a>tensor.view()方法</h2><p>.view方法会返回一个类似视图的结果，通过。view方法还可以改变对象结构，生成一个不同结构，但是是“浅拷贝“</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.arange(<span class="number">6</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">t</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0, 1, 2],
        [3, 4, 5]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">te=t.view(<span class="number">3</span>,<span class="number">2</span>)    <span class="comment"># 构建一个结构不同但数据一样的“视图”</span></span><br><span class="line">te</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0, 1],
        [2, 3],
        [4, 5]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t[<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line">t[<span class="number">1</span>][<span class="number">0</span>]=<span class="number">1</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1, 1, 1],
        [1, 4, 5]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">te   </span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1, 1],
        [1, 1],
        [4, 5]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tr=t.view(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">tr</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[1, 1, 1],
         [1, 4, 5]]])
</code></pre>
<h2 id="张量的分片函数"><a href="#张量的分片函数" class="headerlink" title="张量的分片函数"></a>张量的分片函数</h2><h4 id="1-分块-chunk函数"><a href="#1-分块-chunk函数" class="headerlink" title="1. 分块 chunk函数"></a>1. 分块 chunk函数</h4><p>chunk函数能够按照某维度，对张量进行均匀切分，并返回原张量的视图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=torch.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line">t2</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0,  1,  2],
        [ 3,  4,  5],
        [ 6,  7,  8],
        [ 9, 10, 11]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tc=torch.chunk(t2,<span class="number">4</span>,dim=<span class="number">0</span>) <span class="comment"># 在第零个维度上进行四等分</span></span><br><span class="line">tc</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[0, 1, 2]]),
 tensor([[3, 4, 5]]),
 tensor([[6, 7, 8]]),
 tensor([[ 9, 10, 11]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tc[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([0, 1, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tc[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]=<span class="number">1</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tc</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[1, 1, 2]]),
 tensor([[3, 4, 5]]),
 tensor([[6, 7, 8]]),
 tensor([[ 9, 10, 11]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.size()  <span class="comment"># dim=0 -&gt; 4   dim=1 -&gt; 3</span></span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([4, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tc=torch.chunk(t2,<span class="number">3</span>,dim=<span class="number">1</span>)</span><br><span class="line">tc</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[1],
         [3],
         [6],
         [9]]),
 tensor([[ 1],
         [ 4],
         [ 7],
         [10]]),
 tensor([[ 2],
         [ 5],
         [ 8],
         [11]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tc=torch.chunk(t2,<span class="number">3</span>,dim=<span class="number">0</span>)  <span class="comment"># 当原张量不能均分时，会返回次一级均分的结果</span></span><br><span class="line">tc</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[1, 1, 2],
         [3, 4, 5]]),
 tensor([[ 6,  7,  8],
         [ 9, 10, 11]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.chunk(t2,<span class="number">4</span>) <span class="comment"># 默认dim=0</span></span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[1, 1, 2]]),
 tensor([[3, 4, 5]]),
 tensor([[6, 7, 8]]),
 tensor([[ 9, 10, 11]]))
</code></pre>
<h4 id="2-拆分：split函数"><a href="#2-拆分：split函数" class="headerlink" title="2.拆分：split函数"></a>2.拆分：split函数</h4><p>split既能进行均分也能进行自定义切分，当然，和chunk函数一样，都是返回视图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=torch.arange(<span class="number">12</span>).reshape(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line">t2</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0,  1,  2],
        [ 3,  4,  5],
        [ 6,  7,  8],
        [ 9, 10, 11]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.split(t2,<span class="number">2</span>,<span class="number">0</span>) <span class="comment"># 第二个参数表示切分的序列  第三个参数表示维度</span></span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[0, 1, 2],
         [3, 4, 5]]),
 tensor([[ 6,  7,  8],
         [ 9, 10, 11]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tc=torch.split(t2,[<span class="number">1</span>,<span class="number">3</span>],<span class="number">0</span>)</span><br><span class="line">tc</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[0, 1, 2]]),
 tensor([[ 3,  4,  5],
         [ 6,  7,  8],
         [ 9, 10, 11]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(t2)  <span class="comment"># 序列的和与len()一致</span></span><br></pre></td></tr></table></figure>




<pre><code>4
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tc[<span class="number">1</span>][<span class="number">0</span>]=torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">tc</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[0, 1, 2]]),
 tensor([[ 1,  2,  3],
         [ 6,  7,  8],
         [ 9, 10, 11]]))
</code></pre>
<h4 id="3-拼接"><a href="#3-拼接" class="headerlink" title="3.拼接"></a>3.拼接</h4><p>张量的合并操作类似于列表的追加元素，可以拼接、也可以堆叠</p>
<ul>
<li>拼接函数：cat</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a=torch.zeros(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">a</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b=torch.ones(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1., 1., 1.],
        [1., 1., 1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c=torch.zeros(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">c</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat([a,b])</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.],
        [1., 1., 1.],
        [1., 1., 1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat([a,b],<span class="number">1</span>) <span class="comment"># 按照维度进行拼接，dim默认为0</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0., 0., 0., 1., 1., 1.],
        [0., 0., 0., 1., 1., 1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.car([a,c],<span class="number">1</span>) <span class="comment"># 形状不匹配时会报错</span></span><br></pre></td></tr></table></figure>

<ul>
<li>堆叠函数：stack<br>和拼接不同，堆叠不是将元素拆分重组，而是简单的将各参与堆叠的对象分装到一个更高维度的张量里<br>堆叠要求张量形状都相同</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1., 1., 1.],
        [1., 1., 1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=torch.stack([torch.cat([a,c]),torch.cat([b,c])])</span><br><span class="line">t3</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]],

        [[1., 1., 1.],
         [1., 1., 1.],
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3.size()</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([2, 5, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack([a,b])</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[0., 0., 0.],
         [0., 0., 0.]],

        [[1., 1., 1.],
         [1., 1., 1.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack([a,b]).shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([2, 2, 3])
</code></pre>
<h2 id="张量维度变换"><a href="#张量维度变换" class="headerlink" title="张量维度变换"></a>张量维度变换</h2><p>通过reshape方法可以灵活调整张量的形状，在实际使用中往往要使用升维和降维操作<br>使用squeeze函数进行降维，使用unsqueeze函数进行升维</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a=torch.arange(<span class="number">4</span>)</span><br><span class="line">a</span><br></pre></td></tr></table></figure>




<pre><code>tensor([0, 1, 2, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a2=a.reshape(<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">a2</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0, 1, 2, 3]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.squeeze(a2).ndim</span><br></pre></td></tr></table></figure>




<pre><code>1
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a2=torch.zeros(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">a2</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[[0., 0.]],

         [[0., 0.]]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unsqueeze(a2,dim=<span class="number">0</span>)  <span class="comment"># 在第1个维度索引上升高一个维度</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[[[0., 0.]],

          [[0., 0.]]]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unsqueeze(a2,dim=<span class="number">0</span>).shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([1, 1, 2, 1, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unsqueeze(a2,dim=<span class="number">2</span>).shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([1, 2, 1, 1, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unsqueeze(a2,dim=<span class="number">3</span>).shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([1, 2, 1, 1, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unsqueeze(a2,dim=<span class="number">4</span>).shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([1, 2, 1, 2, 1])
</code></pre>

        </div>

        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/pytorch/">#pytorch</a>&nbsp;
                    </li>
                
            </ul>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2021/07/27/%E5%BC%A0%E9%87%8F%E7%9A%84%E5%B9%BF%E6%92%AD%E5%92%8C%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">张量的广播和科学计算</span>
                                <span class="post-nav-item">上一篇</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2021/07/20/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">自动求导</span>
                                <span class="post-nav-item">下一篇</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2021</span>
              -
            
            2024&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">云间之龙</a>
        </div>
        
        <div class="theme-info info-item">
            由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95"><span class="nav-text">张量的创建与常用方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F%E7%9A%84%E7%B4%A2%E5%BC%95%E3%80%81%E5%88%86%E7%89%87%E3%80%81%E5%90%88%E5%B9%B6%E4%BB%A5%E5%8F%8A%E7%BB%B4%E5%BA%A6%E8%B0%83%E6%95%B4"><span class="nav-text">张量的索引、分片、合并以及维度调整</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%80%E7%BB%B4%E5%BC%A0%E9%87%8F%E7%B4%A2%E5%BC%95"><span class="nav-text">一维张量索引</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E5%BC%A0%E9%87%8F"><span class="nav-text">二维张量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4%E5%BC%A0%E9%87%8F"><span class="nav-text">三维张量</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tensor-view-%E6%96%B9%E6%B3%95"><span class="nav-text">tensor.view()方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F%E7%9A%84%E5%88%86%E7%89%87%E5%87%BD%E6%95%B0"><span class="nav-text">张量的分片函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%88%86%E5%9D%97-chunk%E5%87%BD%E6%95%B0"><span class="nav-text">1. 分块 chunk函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E6%8B%86%E5%88%86%EF%BC%9Asplit%E5%87%BD%E6%95%B0"><span class="nav-text">2.拆分：split函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E6%8B%BC%E6%8E%A5"><span class="nav-text">3.拼接</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2"><span class="nav-text">张量维度变换</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>




    
<script src="/js/lazyload.js"></script>



<div class="post-scripts">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>



</body>
</html>
