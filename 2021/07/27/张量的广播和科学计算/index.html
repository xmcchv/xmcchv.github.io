<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="云间之龙">
    
    <title>
        
            张量的广播和科学计算 |
        
        云间小栈
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
        <link rel="shortcut icon" href="/images/avatar.jpg">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/font/css/fontawesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/font/css/regular.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/font/css/solid.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/font/css/brands.min.css">
    
    <script class="keep-theme-configurations">
    const KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"xmcchv.github.io","root":"/","language":"zh-CN","path":"search.xml"}
    KEEP.theme_config = {"base_info":{"primary_color":"#0066cc","title":"云间小栈","author":"云间之龙","url":"https://xmcchv.github.io","avatar":"/images/avatar.jpg","logo":"/images/avatar.jpg","favicon":"/images/avatar.jpg"},"menu":{"home":"/ || fa-solid fa-home","archives":"/archives || fa-solid fa-box-archive","tags":"/tags  || fa-solid fa-tags","下载站":"https://xmcchv.vercel.app/zh-CN/ || fa-solid fa-download","About":"/about  || fa-solid fa-user-graduate"},"first_screen":{"enable":true,"background_img":"/images/bg.svg","background_img_dark":"/images/bg.svg","description":"凡心所向，素履所往；生如逆旅，一苇以航","hitokoto":false},"social_contact":{"enable":true,"links":{"github":"https://github.com/xmcchv"}},"scroll":{"progress_bar":true,"percent":true,"hide_header":true},"home":{"announcement":"stay hungry, stay foolish","category":true,"tag":true,"post_datetime":"updated"},"post":{"author_badge":{"enable":false,"level_badge":true,"custom_badge":["One","Two","Three"]},"word_count":{"wordcount":false,"min2read":false},"datetime_format":"YYYY-MM-DD HH:mm","copyright_info":true,"share":true,"reward":{"enable":false,"img_link":null,"text":null,"icon":null}},"code_block":{"tools":{"enable":true,"style":"default"},"highlight_theme":"default"},"toc":{"enable":true,"number":false,"expand_all":false,"init_open":true,"layout":"left"},"website_count":{"busuanzi_count":{"enable":false,"site_uv":false,"site_pv":false,"page_pv":false}},"local_search":{"enable":true,"preload":true},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.39"},"waline":{"server_url":null,"reaction":false,"version":"3.3.2"},"giscus":{"repo":null,"repo_id":null,"category":"Announcements","category_id":null,"reactions_enabled":false},"artalk":{"server":null},"disqus":{"shortname":null}},"rss":{"enable":false},"lazyload":{"enable":true},"cdn":{"enable":true,"provider":"cdnjs"},"pjax":{"enable":false},"footer":{"since":2021,"word_count":true,"site_deploy":{"enable":true,"provider":"github","url":null},"record":{"enable":false,"list":[{"code":null,"link":null}]}},"inject":{"enable":false,"css":[null],"js":[null]},"root":"","source_data":{},"version":"4.2.5"}
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"}
    KEEP.language_code_block = {"copy":"复制代码","copied":"已复制","fold":"折叠代码块","folded":"已折叠"}
    KEEP.language_copy_copyright = {"copy":"复制版权信息","copied":"已复制","title":"原文标题","author":"原文作者","link":"原文链接"}
  </script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
</div>



<main class="page-container border-box">
    <!-- home first screen  -->
    

    <!-- page content -->
    <div class="page-main-content border-box">
        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="border-box header-content">
        <div class="left flex-start border-box">
            
                <a class="logo-image border-box" href="/">
                    <img src="/images/avatar.jpg">
                </a>
            
            <a class="site-name border-box" href="/">
               云间小栈
            </a>
        </div>

        <div class="right border-box">
            <div class="pc border-box">
                <ul class="menu-list border-box">
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-home"></i>
                                
                                首页
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/archives">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-box-archive"></i>
                                
                                归档
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/tags">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-tags"></i>
                                
                                标签
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" target="_blank" rel="noopener" href="https://xmcchv.vercel.app/zh-cn/">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-download"></i>
                                
                                下载站
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/about">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-user-graduate"></i>
                                
                                关于
                                
                            </a>
                            
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="menu-text-color fas search fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile border-box flex-start">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list border-box">
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-home"></i>
                                </span>
                            
                            首页
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/archives">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-box-archive"></i>
                                </span>
                            
                            归档
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/tags">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-tags"></i>
                                </span>
                            
                            标签
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" target="_blank" rel="noopener" href="https://xmcchv.vercel.app/zh-cn/">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-download"></i>
                                </span>
                            
                            下载站
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/about">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-user-graduate"></i>
                                </span>
                            
                            关于
                        </a>
                        
                    </label>
                    
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle border-box">

            <div class="main-content border-box">
                

                    
<div class="fade-in-down-animation">
    <div class="post-page-container border-box">
        <div class="post-content-container border-box">
            

            <div class="post-content-bottom border-box">
                
                    <div class="post-title">
                        张量的广播和科学计算
                    </div>
                

                
                    <div class="post-header border-box">
                        
                            <div class="avatar-box border-box">
                                <img src="/images/avatar.jpg">
                            </div>
                        
                        <div class="info-box">
                            <div class="author border-box">
                                <span class="name">xmcchv</span>
                                
                            </div>
                            <div class="meta-info border-box">
                                

<div class="post-meta-info-container border-box post">
    <div class="post-meta-info border-box">
        

        
            <span class="meta-info-item post-create-date">
                <i class="icon fa-solid fa-calendar-plus"></i>&nbsp;
                <span class="datetime">2021-07-27 21:46</span>
            </span>

            
                <span class="meta-info-item post-update-date">
                    <i class="icon fa-solid fa-file-pen"></i>&nbsp;
                    <span class="datetime" data-updated="Wed Oct 30 2024 00:36:29 GMT+0800">2024-10-30 00:36</span>
                </span>
            
        

        

        
            <span class="post-tag meta-info-item border-box">
                <ul class="post-tag-ul">
                    
                            <li class="tag-item"><span class="tag-separator"><i class="icon fas fa-hashtag"></i></span><a href="/tags/pytorch/">pytorch</a></li>
                        
                    
                </ul>
            </span>
        

        
        
        
        
    </div>

    
</div>

                            </div>
                        </div>
                    </div>
                

                <div class="post-content keep-markdown-body ">
                    

                    
                         <h2 id="张量的广播和科学运算"><a class="markdownIt-Anchor" href="#张量的广播和科学运算"></a> 张量的广播和科学运算</h2>
<p>作为pytorch中执行深度学习的基本数据类型，张量也拥有非常多的数学与运算函数和方法，以及对应的一系列计算规则。在pytorch中，能够作用于tensor的运算被统一称作为算子</p>
<ul>
<li>数学运算的分类</li>
</ul>
<ol>
<li>逐点运算（pointwise ops）对tensor中每个元素执行相同的运算操作</li>
<li>规约运算（reduction ops）对某一张两进行操作得出某种总结值</li>
<li>比较运算（comparison ops）对多个张量进行比较运算的相关方法</li>
<li>谱运算（spectral ops）涉及信号处理傅里叶变化的操作</li>
<li>BLAS和LAPACK运算 基础线性代数程序集（Basic Linear Algeria Subprograms）和线性代数包（Linear Algeria Package）中定义的、主要用于现行代数科学计算的函数和方法</li>
<li>其他运算 其他未被归类的数学运算</li>
</ol>
<h3 id="一-张量的广播broadcast特性"><a class="markdownIt-Anchor" href="#一-张量的广播broadcast特性"></a> 一、张量的广播(broadcast)特性</h3>
<p>允许不同形状的张量之间进行计算</p>
<h4 id="1相同形状的张量计算"><a class="markdownIt-Anchor" href="#1相同形状的张量计算"></a> 1.相同形状的张量计算</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.arange(<span class="number">3</span>)</span><br><span class="line">t1</span><br></pre></td></tr></table></figure>
<pre><code>tensor([0, 1, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1+t1</span><br></pre></td></tr></table></figure>
<pre><code>tensor([0, 2, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1*t1</span><br></pre></td></tr></table></figure>
<pre><code>tensor([0, 1, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1**t1</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1, 1, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1/t1</span><br></pre></td></tr></table></figure>
<pre><code>tensor([nan, 1., 1.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]+[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<pre><code>[0, 1, 2, 0, 1, 2]
</code></pre>
<h4 id="2-不同形状的张量计算"><a class="markdownIt-Anchor" href="#2-不同形状的张量计算"></a> 2. 不同形状的张量计算</h4>
<p>广播的特性是在不同形状的张量进行计算时，一个或多个张量通过隐式转化为相同形状的两个张量，但是，并非任何两个不同形状的张量都可以通过广播特性进行计算</p>
<h5 id="21-标量和任意形状的张量"><a class="markdownIt-Anchor" href="#21-标量和任意形状的张量"></a> 2.1 标量和任意形状的张量</h5>
<p>标量可以和任意形状的张量进行计算，计算过程就是标量和张量的每一个元素进行计算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1+<span class="number">1</span></span><br></pre></td></tr></table></figure>
<pre><code>tensor([1, 2, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1*<span class="number">2</span></span><br></pre></td></tr></table></figure>
<pre><code>tensor([0, 2, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(t1+<span class="number">1</span>)**<span class="number">2</span></span><br></pre></td></tr></table></figure>
<pre><code>tensor([1, 4, 9])
</code></pre>
<h5 id="22-相同维度-不同形状的计算"><a class="markdownIt-Anchor" href="#22-相同维度-不同形状的计算"></a> 2.2 相同维度、不同形状的计算</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=torch.zeros(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">t2.shape</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([3, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=torch.zeros(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">t3</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]],

        [[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]],

        [[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t21=torch.ones(<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">t21</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1., 1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t21+t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]])
</code></pre>
<p>此处的广播相当于将t21的形状（1,4）拓展成了t2（3,4）<br />
即复制了第一行三次，然后二者相加<br />
也可理解为 t21的第一行和t2的三行分别进行相加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t22=torch.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">t22</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t22.size()</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([3, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.size()</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([3, 4])
</code></pre>
<p>广播规则：</p>
<ol>
<li>两个张量在一个维度一致，另一个维度上其中一个张量为1</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=torch.ones(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">t3.size()</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([3, 1])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2+t3</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]])
</code></pre>
<ol start="2">
<li>t3的形状为（3,1），t31的形状为（1,3），二者的形状在两个分量上均不同，但都有1存在，因此也可以广播</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t31=torch.ones(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">t31</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t31+t3</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[2., 2., 2.],
        [2., 2., 2.],
        [2., 2., 2.]])
</code></pre>
<p>三维张量的广播</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=torch.zeros(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">t3</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]],

        [[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]],

        [[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t31=torch.ones(<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">t31</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[1.],
         [1.],
         [1.],
         [1.]],

        [[1.],
         [1.],
         [1.],
         [1.]],

        [[1.],
         [1.],
         [1.],
         [1.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3+t31</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]],

        [[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]],

        [[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t32=torch.ones(<span class="number">3</span>,<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line">t32</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[1., 1., 1., 1., 1.]],

        [[1., 1., 1., 1., 1.]],

        [[1., 1., 1., 1., 1.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t32+t3</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]],

        [[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]],

        [[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t32+t31 <span class="comment"># 一维度一致，另两个维度不同，但都有 1</span></span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.]],

        [[2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.]],

        [[2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.],
         [2., 2., 2., 2., 2.]]])
</code></pre>
<h5 id="23不同维度的张量计算过程中的广播"><a class="markdownIt-Anchor" href="#23不同维度的张量计算过程中的广播"></a> 2.3不同维度的张量计算过程中的广播</h5>
<p>低维张量升维，只需要将更高维度上填充1即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=torch.arange(<span class="number">4</span>).reshape(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0, 1],
        [2, 3]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.reshape(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[0, 1],
         [2, 3]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.reshape(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[[0, 1],
          [2, 3]]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=torch.zeros(<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">t3+t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[0., 1.],
         [2., 3.]],

        [[0., 1.],
         [2., 3.]],

        [[0., 1.],
         [2., 3.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=torch.ones(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1.],
        [1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=torch.zeros(<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">t3+t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[1., 1., 1.],
         [1., 1., 1.]],

        [[1., 1., 1.],
         [1., 1., 1.]],

        [[1., 1., 1.],
         [1., 1., 1.]]])
</code></pre>
<h3 id="二-逐点运算"><a class="markdownIt-Anchor" href="#二-逐点运算"></a> 二、逐点运算</h3>
<h4 id="tensor基本数学运算"><a class="markdownIt-Anchor" href="#tensor基本数学运算"></a> tensor基本数学运算</h4>
<table>
<thead>
<tr>
<th style="text-align:left">函数</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">torch.add(t1,t2)</td>
<td style="text-align:left">t1+t2</td>
</tr>
<tr>
<td style="text-align:left">torch.subtract(t1,t2)</td>
<td style="text-align:left">t1-t2</td>
</tr>
<tr>
<td style="text-align:left">torch.multiply(t1,t2)</td>
<td style="text-align:left">t1*t2</td>
</tr>
<tr>
<td style="text-align:left">torch.divide(t1,t2)</td>
<td style="text-align:left">t1/t2</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.tensor([<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">t1</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1, 2])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=torch.tensor([<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([3, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.add(t1,t2)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([4, 6])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.multiply(t1,t2)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([3, 8])
</code></pre>
<h4 id="tensor数值调整函数"><a class="markdownIt-Anchor" href="#tensor数值调整函数"></a> tensor数值调整函数</h4>
<table>
<thead>
<tr>
<th style="text-align:left">函数</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">torch.abs()</td>
<td style="text-align:left">返回绝对值</td>
</tr>
<tr>
<td style="text-align:left">torch.ceil()</td>
<td style="text-align:left">向上取整</td>
</tr>
<tr>
<td style="text-align:left">torch.floor()</td>
<td style="text-align:left">向下取整</td>
</tr>
<tr>
<td style="text-align:left">torch.round()</td>
<td style="text-align:left">四舍五入</td>
</tr>
<tr>
<td style="text-align:left">torch.neg()</td>
<td style="text-align:left">取反</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.randn(<span class="number">5</span>)</span><br><span class="line">t</span><br></pre></td></tr></table></figure>
<pre><code>tensor([-0.4222, -2.3513, -2.0652, -0.3838, -0.2116])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">round</span>(t)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([-0., -2., -2., -0., -0.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t.abs_()</span><br></pre></td></tr></table></figure>
<pre><code>tensor([0.4222, 2.3513, 2.0652, 0.3838, 0.2116])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t.neg_()</span><br></pre></td></tr></table></figure>
<pre><code>tensor([-0.4222, -2.3513, -2.0652, -0.3838, -0.2116])
</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left">数学运算函数</th>
<th style="text-align:left">数学公式</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">幂运算</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.exp(t)</td>
<td style="text-align:left">$ y_{i} = e^{x_{i}} $</td>
<td style="text-align:left">返回以e为底、t中元素为幂的张量</td>
</tr>
<tr>
<td style="text-align:left">torch.expm1(t)</td>
<td style="text-align:left">$ y_{i} = e^{x_{i}} $ - 1</td>
<td style="text-align:left">对张量中的所有元素计算exp（x） - 1</td>
</tr>
<tr>
<td style="text-align:left">torch.exp2(t)</td>
<td style="text-align:left">$ y_{i} = 2^{x_{i}} $</td>
<td style="text-align:left">逐个元素计算2的t次方。</td>
</tr>
<tr>
<td style="text-align:left">torch.pow(t,n)</td>
<td style="text-align:left">$\text{out}_i = x_i ^ \text{exponent} $</td>
<td style="text-align:left">返回t的n次幂</td>
</tr>
<tr>
<td style="text-align:left">torch.sqrt(t)</td>
<td style="text-align:left">$ \text{out}{i} = \sqrt{\text{input}{i}} $</td>
<td style="text-align:left">返回t的平方根</td>
</tr>
<tr>
<td style="text-align:left">torch.square(t)</td>
<td style="text-align:left">$ \text{out}_i = x_i ^ \text{2} $</td>
<td style="text-align:left">返回输入的元素平方。</td>
</tr>
<tr>
<td style="text-align:left">对数运算</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">torch.log10(t)</td>
<td style="text-align:left">$ y_{i} = \log_{10} (x_{i}) $</td>
<td style="text-align:left">返回以10为底的t的对数</td>
</tr>
<tr>
<td style="text-align:left">torch.log(t)</td>
<td style="text-align:left">$ y_{i} = \log_{e} (x_{i}) $</td>
<td style="text-align:left">返回以e为底的t的对数</td>
</tr>
<tr>
<td style="text-align:left">torch.log2(t)</td>
<td style="text-align:left">$ y_{i} = \log_{2} (x_{i}) $</td>
<td style="text-align:left">返回以2为底的t的对数</td>
</tr>
<tr>
<td style="text-align:left">torch.log1p(t)</td>
<td style="text-align:left">$ y_i = \log_{e} (x_i $ + 1)</td>
<td style="text-align:left">返回一个加自然对数的输入数组。</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">pow</span>(torch.tensor(<span class="number">2</span>),<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor(4)
</code></pre>
<ul>
<li>tensor的大多数科学运算具有一定的静态性<br />
静态性就是对输入的张量类型有明确的要求，例如部分函数只能输入浮点型张量，而不能输入整形张量</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.arange(<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">t.dtype</span><br></pre></td></tr></table></figure>
<pre><code>torch.int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1, 2, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.exp(t)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([ 2.7183,  7.3891, 20.0855])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1=t.<span class="built_in">float</span>()</span><br><span class="line">t1</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1., 2., 3.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.exp(t1)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([ 2.7183,  7.3891, 20.0855])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.expm1(t1)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([ 1.7183,  6.3891, 19.0855])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">pow</span>(t,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1, 4, 9])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">pow</span>(t,<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1.0000, 1.4142, 1.7321])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.exp(torch.log(t1))</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1., 2., 3.])
</code></pre>
<ul>
<li>排序运算：sort<br />
在pytorch中，sort函数将同时返回排序结果和对应的索引值的排列</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.tensor([<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>])</span><br><span class="line">t</span><br></pre></td></tr></table></figure>
<pre><code>tensor([1, 3, 2, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sort(t)</span><br></pre></td></tr></table></figure>
<pre><code>torch.return_types.sort(
values=tensor([1, 2, 3, 4]),
indices=tensor([0, 2, 1, 3]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sort(t,descending=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<pre><code>torch.return_types.sort(
values=tensor([4, 3, 2, 1]),
indices=tensor([3, 1, 2, 0]))
</code></pre>
<h3 id="三-规约运算"><a class="markdownIt-Anchor" href="#三-规约运算"></a> 三、规约运算</h3>
<p>规约运算指针对某张量进行某种总结，最后得出一个具体总结值的函数。主要包含数据科学领域内的诸多统计分析函数，如均值、极值、方差、中位数函数等等。</p>
<table>
<thead>
<tr>
<th style="text-align:left">函数</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">torch.mean(t)</td>
<td style="text-align:left">返回张量均值</td>
</tr>
<tr>
<td style="text-align:left">torch.var(t)</td>
<td style="text-align:left">返回张量方差</td>
</tr>
<tr>
<td style="text-align:left">torch.std(t)</td>
<td style="text-align:left">返回张量标准差</td>
</tr>
<tr>
<td style="text-align:left">torch.var_mean(t)</td>
<td style="text-align:left">返回张量方差和均值</td>
</tr>
<tr>
<td style="text-align:left">torch.std_mean(t)</td>
<td style="text-align:left">返回张量标准差和均值</td>
</tr>
<tr>
<td style="text-align:left">torch.max(t)</td>
<td style="text-align:left">返回张量最大值</td>
</tr>
<tr>
<td style="text-align:left">torch.argmax(t)</td>
<td style="text-align:left">返回张量最大值索引</td>
</tr>
<tr>
<td style="text-align:left">torch.min(t)</td>
<td style="text-align:left">返回张量最小值</td>
</tr>
<tr>
<td style="text-align:left">torch.argmin(t)</td>
<td style="text-align:left">返回张量最小值索引</td>
</tr>
<tr>
<td style="text-align:left">torch.median(t)</td>
<td style="text-align:left">返回张量中位数</td>
</tr>
<tr>
<td style="text-align:left">torch.sum(t)</td>
<td style="text-align:left">返回张量求和结果</td>
</tr>
<tr>
<td style="text-align:left">torch.logsumexp(t)</td>
<td style="text-align:left">返回张量各元素求和结果，适用于数据量较小的情况</td>
</tr>
<tr>
<td style="text-align:left">torch.prod(t)</td>
<td style="text-align:left">返回张量累乘结果</td>
</tr>
<tr>
<td style="text-align:left">torch.dist(t1, t2)</td>
<td style="text-align:left">计算两个张量的闵式距离，可使用不同范式</td>
</tr>
<tr>
<td style="text-align:left">torch.topk(t)</td>
<td style="text-align:left">返回t中最大的k个值对应的指标</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t=torch.arange(<span class="number">10</span>).<span class="built_in">float</span>()</span><br><span class="line">t</span><br></pre></td></tr></table></figure>
<pre><code>tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.std_mean(t)</span><br></pre></td></tr></table></figure>
<pre><code>(tensor(3.0277), tensor(4.5000))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.prod(torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>tensor(24)
</code></pre>
<ul>
<li>dist计算距离<br />
dist函数可计算闵式距离(闵可夫斯基距离)，通过输入不同的p值，可以计算多种类型的距离，如欧式距离，街道距离等。闵可夫斯基距离公式表示如下：</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><munderover><mo>∑</mo><mrow><mi>u</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>u</mi></msub><mo>−</mo><msub><mi>y</mi><mi>u</mi></msub><mi mathvariant="normal">∣</mi></mrow><mi>p</mi></msup><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>p</mi></mrow></msup></mrow><annotation encoding="application/x-tex">D(x,y)=(\sum_{u=1}^{n}{|x_{u}-y_{u}|}^{p} )^{1/p}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.9185100000000004em;vertical-align:-1.267113em;"></span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-3.2029000000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">/</span><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>p取值为2时，计算欧式距离</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.tensor([<span class="number">1.0</span>,<span class="number">2</span>])</span><br><span class="line">t2=torch.tensor([<span class="number">3.0</span>,<span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.dist(t1,t2,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor(2.8284)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sqrt(torch.tensor(<span class="number">8.0</span>))</span><br></pre></td></tr></table></figure>
<pre><code>tensor(2.8284)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.dist(t1,t2,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor(4.)
</code></pre>
<ul>
<li>规约运算的维度<br />
由于规约运算是一个序列返回一个结果，因此若是针对高维张良，则可能指定某维度进行计算。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=torch.arange(<span class="number">12</span>).<span class="built_in">float</span>().reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.shape</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([3, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">sum</span>(t2,dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([12., 15., 18., 21.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">sum</span>(t2,dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([ 6., 22., 38.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t3=torch.arange(<span class="number">24</span>).<span class="built_in">float</span>().reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">t3</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.]],

        [[12., 13., 14., 15.],
         [16., 17., 18., 19.],
         [20., 21., 22., 23.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t3.shape</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([2, 3, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">sum</span>(t3,dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[12., 14., 16., 18.],
        [20., 22., 24., 26.],
        [28., 30., 32., 34.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">sum</span>(t3,dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[12., 15., 18., 21.],
        [48., 51., 54., 57.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">sum</span>(t3,dim=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[ 6., 22., 38.],
        [54., 70., 86.]])
</code></pre>
<ul>
<li>二维张量的排序</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t22=torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">t22</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[-0.1265,  0.2807,  0.7180,  0.8772],
        [ 1.9022,  0.3509, -0.4520, -2.3835],
        [-0.5028, -0.8871, -2.2325,  0.7211]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sort(t22) <span class="comment"># 默认情况下，按照行进行升序排序</span></span><br></pre></td></tr></table></figure>
<pre><code>torch.return_types.sort(
values=tensor([[-0.1265,  0.2807,  0.7180,  0.8772],
        [-2.3835, -0.4520,  0.3509,  1.9022],
        [-2.2325, -0.8871, -0.5028,  0.7211]]),
indices=tensor([[0, 1, 2, 3],
        [3, 2, 1, 0],
        [2, 1, 0, 3]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sort(t22,dim=<span class="number">1</span>,descending=<span class="literal">True</span>) <span class="comment"># 按列降序排序</span></span><br></pre></td></tr></table></figure>
<pre><code>torch.return_types.sort(
values=tensor([[ 0.8772,  0.7180,  0.2807, -0.1265],
        [ 1.9022,  0.3509, -0.4520, -2.3835],
        [ 0.7211, -0.5028, -0.8871, -2.2325]]),
indices=tensor([[3, 2, 1, 0],
        [0, 1, 2, 3],
        [3, 0, 1, 2]]))
</code></pre>
<h3 id="四-比较运算"><a class="markdownIt-Anchor" href="#四-比较运算"></a> 四、比较运算</h3>
<p>比较运算是一类较为简单的运算类型，和python原生的布尔运算类似，常用于不同张量之间的逻辑运算，最终返回逻辑运算结果（逻辑类型张量）基本比较运算函数如下所示：</p>
<table>
<thead>
<tr>
<th style="text-align:left">函数</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">torch.eq(t1,t2)</td>
<td style="text-align:left">等效==</td>
</tr>
<tr>
<td style="text-align:left">torch.equal(t1,t2)</td>
<td style="text-align:left">判断两个张量是否是相同的张量</td>
</tr>
<tr>
<td style="text-align:left"><a class="link"   target="_blank" rel="noopener" href="http://torch.gt" >torch.gt<i class="fas fa-external-link-alt"></i></a>(t1,t2)</td>
<td style="text-align:left">等效&gt;</td>
</tr>
<tr>
<td style="text-align:left"><a class="link"   target="_blank" rel="noopener" href="http://torch.lt" >torch.lt<i class="fas fa-external-link-alt"></i></a>(t1,t2)</td>
<td style="text-align:left">等效于&lt;</td>
</tr>
<tr>
<td style="text-align:left"><a class="link"   target="_blank" rel="noopener" href="http://torch.ge" >torch.ge<i class="fas fa-external-link-alt"></i></a>(t1,t2)</td>
<td style="text-align:left">等效&gt;=</td>
</tr>
<tr>
<td style="text-align:left">torch.le(t1,t2)</td>
<td style="text-align:left">等效&lt;=</td>
</tr>
<tr>
<td style="text-align:left"><a class="link"   target="_blank" rel="noopener" href="http://torch.ne" >torch.ne<i class="fas fa-external-link-alt"></i></a>(t1,t2)</td>
<td style="text-align:left">等效!=</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t1=torch.tensor([<span class="number">1.0</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">t2=torch.tensor([<span class="number">1.0</span>,<span class="number">2</span>,<span class="number">5</span>])</span><br><span class="line">t1==t2</span><br></pre></td></tr></table></figure>
<pre><code>tensor([ True, False, False])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.equal(t1,t2)</span><br></pre></td></tr></table></figure>
<pre><code>False
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.eq(t1,t2)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([ True, False, False])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.lt(t1,t2)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([False, False,  True])
</code></pre>

                    
                </div>

                
                        
<div class="post-copyright-info-container border-box">
    <div class="copyright-info-content border-box">
        <div class="copyright-info-top border-box">
            <div class="copyright-post-title border-box text-ellipsis">
                张量的广播和科学计算
            </div>

            <div class="copyright-post-link border-box text-ellipsis">
                2021/07/27/张量的广播和科学计算/
            </div>
        </div>

        <div class="copyright-info-bottom border-box">
            <div class="copyright-post-author bottom-item">
                <div class="type">
                    作者
                </div>
                <div class="content">云间之龙</div>
            </div>

            <div class="post-time bottom-item">
                <div class="type">
                    发布于
                </div>
                <div class="content">2021-07-27 21:46</div>
            </div>


            <div class="post-license bottom-item">
                <div class="type">
                    许可
                </div>
                <div class="content tooltip" data-tooltip-content="CC BY-NC-SA 4.0">
                    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" target="_blank">
                        
                            <i class="fa-brands fa-creative-commons"></i>
                            <i class="fa-brands fa-creative-commons-by"></i>
                            <i class="fa-brands fa-creative-commons-nc"></i>
                            <i class="fa-brands fa-creative-commons-sa"></i>
                        
                    </a>
                </div>
            </div>
        </div>

        <i class="copyright-bg fa-solid fa-copyright"></i>
    </div>
    <div class="copy-copyright-info flex-center tooltip" data-tooltip-content="复制版权信息" data-tooltip-offset-y="-2px">
        <i class="fa-solid fa-copy"></i>
    </div>
</div>

                

                <div class="post-bottom-tags-and-share border-box">
                    <div>
                        
                            <ul class="post-tags-box border-box">
                                
                                    <li class="tag-item border-box">
                                        <i class="icon fas fa-hashtag"></i>&nbsp;<a href="/tags/pytorch/">pytorch</a>
                                    </li>
                                
                            </ul>
                        
                    </div>
                    <div>
                        
                            <div class="post-share-container border-box">
    <ul class="share-list-wrap border-box">
        <li class="qq share-item border-box flex-center tooltip"
            data-tooltip-content="分享到 QQ"
        >
            <i class="fa-brands fa-qq"></i>
        </li>
        <li class="wechat share-item border-box flex-center tooltip tooltip-img"
            data-tooltip-content="分享到微信"
            data-tooltip-img-tip="微信扫一扫"
            data-tooltip-img-style="background-color: #fff; top: -10px; padding: 0.6rem 0.6rem 0.1rem 0.6rem;"
        >
            <i class="fa-brands fa-weixin"></i>
        </li>
        <li class="weibo share-item border-box flex-center tooltip"
            data-tooltip-content="分享到微博"
        >
            <i class="fa-brands fa-weibo"></i>
        </li>
    </ul>
</div>

                        
                    </div>
                </div>

                

                
                    <div class="post-nav border-box">
                        
                            <div class="prev-post">
                                <a class="prev"
                                   rel="prev"
                                   href="/2021/07/31/%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E8%BF%90%E7%AE%97/"
                                   title="张量的线性代数运算"
                                >
                                    <span class="left arrow-icon flex-center">
                                        <i class="fas fa-chevron-left"></i>
                                    </span>
                                    <span class="title flex-center">
                                        <span class="post-nav-title-item text-ellipsis">张量的线性代数运算</span>
                                        <span class="post-nav-item">上一篇</span>
                                    </span>
                                </a>
                            </div>
                        
                        
                            <div class="next-post">
                                <a class="next"
                                   rel="next"
                                   href="/2021/07/24/tensor%E5%9F%BA%E7%A1%80/"
                                   title="tensor基础"
                                >
                                    <span class="title flex-center">
                                        <span class="post-nav-title-item text-ellipsis">tensor基础</span>
                                        <span class="post-nav-item">下一篇</span>
                                    </span>
                                    <span class="right arrow-icon flex-center">
                                        <i class="fas fa-chevron-right"></i>
                                    </span>
                                </a>
                            </div>
                        
                    </div>
                

                
                    






                
            </div>
        </div>

        
            <div class="pc-post-toc left-toc">
                <div class="post-toc-wrap border-box">
    <div class="post-toc border-box">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F%E7%9A%84%E5%B9%BF%E6%92%AD%E5%92%8C%E7%A7%91%E5%AD%A6%E8%BF%90%E7%AE%97"><span class="nav-text"> 张量的广播和科学运算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80-%E5%BC%A0%E9%87%8F%E7%9A%84%E5%B9%BF%E6%92%ADbroadcast%E7%89%B9%E6%80%A7"><span class="nav-text"> 一、张量的广播(broadcast)特性</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E7%9B%B8%E5%90%8C%E5%BD%A2%E7%8A%B6%E7%9A%84%E5%BC%A0%E9%87%8F%E8%AE%A1%E7%AE%97"><span class="nav-text"> 1.相同形状的张量计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E4%B8%8D%E5%90%8C%E5%BD%A2%E7%8A%B6%E7%9A%84%E5%BC%A0%E9%87%8F%E8%AE%A1%E7%AE%97"><span class="nav-text"> 2. 不同形状的张量计算</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#21-%E6%A0%87%E9%87%8F%E5%92%8C%E4%BB%BB%E6%84%8F%E5%BD%A2%E7%8A%B6%E7%9A%84%E5%BC%A0%E9%87%8F"><span class="nav-text"> 2.1 标量和任意形状的张量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#22-%E7%9B%B8%E5%90%8C%E7%BB%B4%E5%BA%A6-%E4%B8%8D%E5%90%8C%E5%BD%A2%E7%8A%B6%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-text"> 2.2 相同维度、不同形状的计算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#23%E4%B8%8D%E5%90%8C%E7%BB%B4%E5%BA%A6%E7%9A%84%E5%BC%A0%E9%87%8F%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%B9%BF%E6%92%AD"><span class="nav-text"> 2.3不同维度的张量计算过程中的广播</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C-%E9%80%90%E7%82%B9%E8%BF%90%E7%AE%97"><span class="nav-text"> 二、逐点运算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#tensor%E5%9F%BA%E6%9C%AC%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97"><span class="nav-text"> tensor基本数学运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tensor%E6%95%B0%E5%80%BC%E8%B0%83%E6%95%B4%E5%87%BD%E6%95%B0"><span class="nav-text"> tensor数值调整函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89-%E8%A7%84%E7%BA%A6%E8%BF%90%E7%AE%97"><span class="nav-text"> 三、规约运算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B-%E6%AF%94%E8%BE%83%E8%BF%90%E7%AE%97"><span class="nav-text"> 四、比较运算</span></a></li></ol></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>
        </div>

        <div class="page-main-content-bottom border-box">
            
<footer class="footer border-box">
    <div class="copyright-info info-item">
    &copy;&nbsp;<span>2021</span>&nbsp;-&nbsp;2025
    
            &nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;&nbsp;<a href="/">云间之龙</a>
        
    </div>

    <div class="theme-info info-item">
        由&nbsp;<a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;驱动&nbsp;&&nbsp;主题&nbsp;<a class="keep-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep</a>
    </div>

    
        
        <div class="deploy-info info-item">
            
            本站由 <span class="tooltip" data-tooltip-content="GitHub Pages"><img src="/images/brands/github.png"></span> 提供部署服务
            
        </div>
    

    

    
</footer>

        </div>
    </div>

    <!-- post tools -->
    
        <div class="post-tools left-toc">
            <div class="post-tools-container border-box">
    <ul class="post-tools-list border-box">
        <!-- PC encrypt again -->
        

        <!-- PC TOC show toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- PC go comment -->
        

        <!-- PC full screen -->
        <li class="tools-item flex-center full-screen">
            <i class="fa-solid fa-expand"></i>
        </li>
    </ul>
</div>

        </div>
    

    <!-- side tools -->
    <div class="side-tools">
        <div class="side-tools-container border-box ">
    <ul class="side-tools-list side-tools-show-handle border-box">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <!-- toggle mode -->
        
            <li class="tools-item tool-toggle-theme-mode flex-center">
                <i class="fas fa-moon"></i>
            </li>
        

        <!-- rss -->
        

        <!-- to bottom -->
        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list border-box">
        
            <li class="tools-item toggle-show-toc-tablet flex-center">
                <i class="fas fa-list"></i>
            </li>
        

        

        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>

        <li class="tools-item tool-scroll-to-top flex-center show-arrow">
            <i class="arrow fas fa-arrow-up"></i>
            <span class="percent"></span>
        </li>
    </ul>
</div>

    </div>

    <!-- image mask -->
    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    <!-- local search -->
    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

    <!-- tablet toc -->
    
        <div class="tablet-post-toc-mask">
            <div class="tablet-post-toc">
                <div class="post-toc-wrap border-box">
    <div class="post-toc border-box">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F%E7%9A%84%E5%B9%BF%E6%92%AD%E5%92%8C%E7%A7%91%E5%AD%A6%E8%BF%90%E7%AE%97"><span class="nav-text"> 张量的广播和科学运算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80-%E5%BC%A0%E9%87%8F%E7%9A%84%E5%B9%BF%E6%92%ADbroadcast%E7%89%B9%E6%80%A7"><span class="nav-text"> 一、张量的广播(broadcast)特性</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E7%9B%B8%E5%90%8C%E5%BD%A2%E7%8A%B6%E7%9A%84%E5%BC%A0%E9%87%8F%E8%AE%A1%E7%AE%97"><span class="nav-text"> 1.相同形状的张量计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E4%B8%8D%E5%90%8C%E5%BD%A2%E7%8A%B6%E7%9A%84%E5%BC%A0%E9%87%8F%E8%AE%A1%E7%AE%97"><span class="nav-text"> 2. 不同形状的张量计算</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#21-%E6%A0%87%E9%87%8F%E5%92%8C%E4%BB%BB%E6%84%8F%E5%BD%A2%E7%8A%B6%E7%9A%84%E5%BC%A0%E9%87%8F"><span class="nav-text"> 2.1 标量和任意形状的张量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#22-%E7%9B%B8%E5%90%8C%E7%BB%B4%E5%BA%A6-%E4%B8%8D%E5%90%8C%E5%BD%A2%E7%8A%B6%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-text"> 2.2 相同维度、不同形状的计算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#23%E4%B8%8D%E5%90%8C%E7%BB%B4%E5%BA%A6%E7%9A%84%E5%BC%A0%E9%87%8F%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%B9%BF%E6%92%AD"><span class="nav-text"> 2.3不同维度的张量计算过程中的广播</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C-%E9%80%90%E7%82%B9%E8%BF%90%E7%AE%97"><span class="nav-text"> 二、逐点运算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#tensor%E5%9F%BA%E6%9C%AC%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97"><span class="nav-text"> tensor基本数学运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tensor%E6%95%B0%E5%80%BC%E8%B0%83%E6%95%B4%E5%87%BD%E6%95%B0"><span class="nav-text"> tensor数值调整函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89-%E8%A7%84%E7%BA%A6%E8%BF%90%E7%AE%97"><span class="nav-text"> 三、规约运算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B-%E6%AF%94%E8%BE%83%E8%BF%90%E7%AE%97"><span class="nav-text"> 四、比较运算</span></a></li></ol></li></ol>
    </div>
</div>

            </div>
        </div>
    
</main>





<!-- common js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/header-shrink.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/back2top.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/toggle-theme.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/code-block.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/main.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/libs/anime.min.js"></script>

<!-- local search -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/local-search.min.js"></script>


<!-- lazyload -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/lazyload.min.js"></script>


<div class="">
    <!-- home page -->
    

    <!-- post page -->
    
        <!-- post-helper -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/post/post-helper.min.js"></script>

        <!-- toc -->
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/post/toc.min.js"></script>
        

        <!-- copyright-info -->
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/post/copyright-info.min.js"></script>
        

        <!-- share -->
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.5/js/post/share.min.js"></script>
        
    

    <!-- categories page -->
    

    <!-- links page -->
    

    <!-- photos page -->
    

    <!-- tools page -->
    
</div>

<!-- mermaid -->


<!-- pjax -->



</body>
</html>
